bertscore_precision_hyp_vs_ref, 0.408,bertscore_recall_hyp_vs_ref, 0.474,bertscore_f1_hyp_vs_ref, 0.44,bertscore_precision_hyp_vs_src, 0.638,bertscore_recall_hyp_vs_src, 0.523,bertscore_f1_hyp_vs_src, 0.579,, experiment_path, experiments/x_ablation_study/llama_3_70b_instruct_sglang/WordCount/level-4_feedbackloop_prompt-gold-filtered_wiki.valid_v1.1.src-100_llama_3_70b_instruct_sglang_examples_5_temp_0_chain_True_seed_368914
