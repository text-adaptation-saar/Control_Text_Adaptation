bertscore_precision_hyp_vs_ref, 0.371,bertscore_recall_hyp_vs_ref, 0.494,bertscore_f1_hyp_vs_ref, 0.431,bertscore_precision_hyp_vs_src, 0.754,bertscore_recall_hyp_vs_src, 0.731,bertscore_f1_hyp_vs_src, 0.742,, experiment_path, experiments/x_ablation_study/llama_3_70b_instruct_sglang/MaxDepDepth/level-3_prompt/level-3_prompt-gold-filtered_wiki.valid_v1.1.src-100_llama_3_70b_instruct_sglang_examples_0_temp_0_chain_False_seed_921405
