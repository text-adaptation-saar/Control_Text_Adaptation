bertscore_precision_hyp_vs_ref, 0.147,bertscore_recall_hyp_vs_ref, -0.101,bertscore_f1_hyp_vs_ref, 0.018,bertscore_precision_hyp_vs_src, 0.272,bertscore_recall_hyp_vs_src, -0.115,bertscore_f1_hyp_vs_src, 0.071,, experiment_path, experiments/train_v3_and_val_v1.1_wo_line_46/grade_level_eval_with_cot_feedback_prompt/0_catboost_swetas_fkgl_train_2_all_9input_7output/f4_maxdepdepth_maxdeplength_diffwords_wc/llama_3_70b_instruct_sglang/cot_feedback_with_catboost_swetas-filtered_wiki.valid_v1.1.src-200_llama_3_70b_instruct_sglang_examples_5_temp_0_chain_True_seed_473829/maxdepdepth_-1_maxdeplength_-1_diffwordscount_-1_avgwordcount_-1_length_-1_leven_-1_grade_1
bertscore_precision_hyp_vs_ref, 0.279,bertscore_recall_hyp_vs_ref, 0.101,bertscore_f1_hyp_vs_ref, 0.187,bertscore_precision_hyp_vs_src, 0.49,bertscore_recall_hyp_vs_src, 0.152,bertscore_f1_hyp_vs_src, 0.315,, experiment_path, experiments/train_v3_and_val_v1.1_wo_line_46/grade_level_eval_with_cot_feedback_prompt/0_catboost_swetas_fkgl_train_2_all_9input_7output/f4_maxdepdepth_maxdeplength_diffwords_wc/llama_3_70b_instruct_sglang/cot_feedback_with_catboost_swetas-filtered_wiki.valid_v1.1.src-200_llama_3_70b_instruct_sglang_examples_5_temp_0_chain_True_seed_473829/maxdepdepth_-1_maxdeplength_-1_diffwordscount_-1_avgwordcount_-1_length_-1_leven_-1_grade_2
bertscore_precision_hyp_vs_ref, 0.207,bertscore_recall_hyp_vs_ref, 0.029,bertscore_f1_hyp_vs_ref, 0.115,bertscore_precision_hyp_vs_src, 0.424,bertscore_recall_hyp_vs_src, 0.081,bertscore_f1_hyp_vs_src, 0.246,, experiment_path, experiments/train_v3_and_val_v1.1_wo_line_46/grade_level_eval_with_cot_feedback_prompt/0_catboost_swetas_fkgl_train_2_all_9input_7output/f4_maxdepdepth_maxdeplength_diffwords_wc/llama_3_70b_instruct_sglang/cot_feedback_with_catboost_swetas-filtered_wiki.valid_v1.1.src-200_llama_3_70b_instruct_sglang_examples_5_temp_0_chain_True_seed_473829/maxdepdepth_-1_maxdeplength_-1_diffwordscount_-1_avgwordcount_-1_length_-1_leven_-1_grade_3
bertscore_precision_hyp_vs_ref, 0.267,bertscore_recall_hyp_vs_ref, 0.158,bertscore_f1_hyp_vs_ref, 0.21,bertscore_precision_hyp_vs_src, 0.557,bertscore_recall_hyp_vs_src, 0.277,bertscore_f1_hyp_vs_src, 0.412,, experiment_path, experiments/train_v3_and_val_v1.1_wo_line_46/grade_level_eval_with_cot_feedback_prompt/0_catboost_swetas_fkgl_train_2_all_9input_7output/f4_maxdepdepth_maxdeplength_diffwords_wc/llama_3_70b_instruct_sglang/cot_feedback_with_catboost_swetas-filtered_wiki.valid_v1.1.src-200_llama_3_70b_instruct_sglang_examples_5_temp_0_chain_True_seed_473829/maxdepdepth_-1_maxdeplength_-1_diffwordscount_-1_avgwordcount_-1_length_-1_leven_-1_grade_4
bertscore_precision_hyp_vs_ref, 0.353,bertscore_recall_hyp_vs_ref, 0.326,bertscore_f1_hyp_vs_ref, 0.338,bertscore_precision_hyp_vs_src, 0.695,bertscore_recall_hyp_vs_src, 0.507,bertscore_f1_hyp_vs_src, 0.599,, experiment_path, experiments/train_v3_and_val_v1.1_wo_line_46/grade_level_eval_with_cot_feedback_prompt/0_catboost_swetas_fkgl_train_2_all_9input_7output/f4_maxdepdepth_maxdeplength_diffwords_wc/llama_3_70b_instruct_sglang/cot_feedback_with_catboost_swetas-filtered_wiki.valid_v1.1.src-200_llama_3_70b_instruct_sglang_examples_5_temp_0_chain_True_seed_473829/maxdepdepth_-1_maxdeplength_-1_diffwordscount_-1_avgwordcount_-1_length_-1_leven_-1_grade_5
bertscore_precision_hyp_vs_ref, 0.396,bertscore_recall_hyp_vs_ref, 0.364,bertscore_f1_hyp_vs_ref, 0.378,bertscore_precision_hyp_vs_src, 0.736,bertscore_recall_hyp_vs_src, 0.528,bertscore_f1_hyp_vs_src, 0.629,, experiment_path, experiments/train_v3_and_val_v1.1_wo_line_46/grade_level_eval_with_cot_feedback_prompt/0_catboost_swetas_fkgl_train_2_all_9input_7output/f4_maxdepdepth_maxdeplength_diffwords_wc/llama_3_70b_instruct_sglang/cot_feedback_with_catboost_swetas-filtered_wiki.valid_v1.1.src-200_llama_3_70b_instruct_sglang_examples_5_temp_0_chain_True_seed_473829/maxdepdepth_-1_maxdeplength_-1_diffwordscount_-1_avgwordcount_-1_length_-1_leven_-1_grade_6
bertscore_precision_hyp_vs_ref, 0.311,bertscore_recall_hyp_vs_ref, 0.311,bertscore_f1_hyp_vs_ref, 0.309,bertscore_precision_hyp_vs_src, 0.668,bertscore_recall_hyp_vs_src, 0.492,bertscore_f1_hyp_vs_src, 0.578,, experiment_path, experiments/train_v3_and_val_v1.1_wo_line_46/grade_level_eval_with_cot_feedback_prompt/0_catboost_swetas_fkgl_train_2_all_9input_7output/f4_maxdepdepth_maxdeplength_diffwords_wc/llama_3_70b_instruct_sglang/cot_feedback_with_catboost_swetas-filtered_wiki.valid_v1.1.src-200_llama_3_70b_instruct_sglang_examples_5_temp_0_chain_True_seed_473829/maxdepdepth_-1_maxdeplength_-1_diffwordscount_-1_avgwordcount_-1_length_-1_leven_-1_grade_7
bertscore_precision_hyp_vs_ref, 0.31,bertscore_recall_hyp_vs_ref, 0.289,bertscore_f1_hyp_vs_ref, 0.298,bertscore_precision_hyp_vs_src, 0.664,bertscore_recall_hyp_vs_src, 0.459,bertscore_f1_hyp_vs_src, 0.559,, experiment_path, experiments/train_v3_and_val_v1.1_wo_line_46/grade_level_eval_with_cot_feedback_prompt/0_catboost_swetas_fkgl_train_2_all_9input_7output/f4_maxdepdepth_maxdeplength_diffwords_wc/llama_3_70b_instruct_sglang/cot_feedback_with_catboost_swetas-filtered_wiki.valid_v1.1.src-200_llama_3_70b_instruct_sglang_examples_5_temp_0_chain_True_seed_473829/maxdepdepth_-1_maxdeplength_-1_diffwordscount_-1_avgwordcount_-1_length_-1_leven_-1_grade_8
bertscore_precision_hyp_vs_ref, 0.389,bertscore_recall_hyp_vs_ref, 0.368,bertscore_f1_hyp_vs_ref, 0.377,bertscore_precision_hyp_vs_src, 0.738,bertscore_recall_hyp_vs_src, 0.542,bertscore_f1_hyp_vs_src, 0.637,, experiment_path, experiments/train_v3_and_val_v1.1_wo_line_46/grade_level_eval_with_cot_feedback_prompt/0_catboost_swetas_fkgl_train_2_all_9input_7output/f4_maxdepdepth_maxdeplength_diffwords_wc/llama_3_70b_instruct_sglang/cot_feedback_with_catboost_swetas-filtered_wiki.valid_v1.1.src-200_llama_3_70b_instruct_sglang_examples_5_temp_0_chain_True_seed_473829/maxdepdepth_-1_maxdeplength_-1_diffwordscount_-1_avgwordcount_-1_length_-1_leven_-1_grade_9
bertscore_precision_hyp_vs_ref, 0.378,bertscore_recall_hyp_vs_ref, 0.438,bertscore_f1_hyp_vs_ref, 0.406,bertscore_precision_hyp_vs_src, 0.785,bertscore_recall_hyp_vs_src, 0.689,bertscore_f1_hyp_vs_src, 0.736,, experiment_path, experiments/train_v3_and_val_v1.1_wo_line_46/grade_level_eval_with_cot_feedback_prompt/0_catboost_swetas_fkgl_train_2_all_9input_7output/f4_maxdepdepth_maxdeplength_diffwords_wc/llama_3_70b_instruct_sglang/cot_feedback_with_catboost_swetas-filtered_wiki.valid_v1.1.src-200_llama_3_70b_instruct_sglang_examples_5_temp_0_chain_True_seed_473829/maxdepdepth_-1_maxdeplength_-1_diffwordscount_-1_avgwordcount_-1_length_-1_leven_-1_grade_10
bertscore_precision_hyp_vs_ref, 0.293,bertscore_recall_hyp_vs_ref, 0.375,bertscore_f1_hyp_vs_ref, 0.332,bertscore_precision_hyp_vs_src, 0.696,bertscore_recall_hyp_vs_src, 0.646,bertscore_f1_hyp_vs_src, 0.671,, experiment_path, experiments/train_v3_and_val_v1.1_wo_line_46/grade_level_eval_with_cot_feedback_prompt/0_catboost_swetas_fkgl_train_2_all_9input_7output/f4_maxdepdepth_maxdeplength_diffwords_wc/llama_3_70b_instruct_sglang/cot_feedback_with_catboost_swetas-filtered_wiki.valid_v1.1.src-200_llama_3_70b_instruct_sglang_examples_5_temp_0_chain_True_seed_473829/maxdepdepth_-1_maxdeplength_-1_diffwordscount_-1_avgwordcount_-1_length_-1_leven_-1_grade_11
bertscore_precision_hyp_vs_ref, 0.321,bertscore_recall_hyp_vs_ref, 0.426,bertscore_f1_hyp_vs_ref, 0.372,bertscore_precision_hyp_vs_src, 0.724,bertscore_recall_hyp_vs_src, 0.708,bertscore_f1_hyp_vs_src, 0.716,, experiment_path, experiments/train_v3_and_val_v1.1_wo_line_46/grade_level_eval_with_cot_feedback_prompt/0_catboost_swetas_fkgl_train_2_all_9input_7output/f4_maxdepdepth_maxdeplength_diffwords_wc/llama_3_70b_instruct_sglang/cot_feedback_with_catboost_swetas-filtered_wiki.valid_v1.1.src-200_llama_3_70b_instruct_sglang_examples_5_temp_0_chain_True_seed_473829/maxdepdepth_-1_maxdeplength_-1_diffwordscount_-1_avgwordcount_-1_length_-1_leven_-1_grade_12
